{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gymnasium.utils as utils \n",
    "import mujoco as m \n",
    "import gymnasium as gym \n",
    "from gymnasium.envs.mujoco.mujoco_env import MujocoEnv\n",
    "from gymnasium.spaces  import Box\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.23.5)\n",
      "Requirement already satisfied: gymnasium in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.28.1)\n",
      "Requirement already satisfied: mujoco in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: torch in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (2.0.0+cu117)\n",
      "Requirement already satisfied: jax-jumpy>=1.0.0 in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from gymnasium) (4.4.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: pyopengl in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mujoco) (3.1.6)\n",
      "Requirement already satisfied: glfw in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mujoco) (2.5.7)\n",
      "Requirement already satisfied: absl-py in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mujoco) (1.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from sympy->torch) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install numpy gymnasium mujoco torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray) (4.17.3)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray) (1.0.5)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray) (3.20.3)\n",
      "Requirement already satisfied: requests in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from ray) (2.28.1)\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray) (20.21.0)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray) (1.53.0)\n",
      "Requirement already satisfied: attrs in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray) (22.2.0)\n",
      "Requirement already satisfied: frozenlist in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray) (1.3.3)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray) (6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from ray) (23.0)\n",
      "Requirement already satisfied: aiosignal in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.19.3 in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray) (1.23.5)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from ray) (8.1.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from ray) (3.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from click>=7.0->ray) (0.4.6)\n",
      "Requirement already satisfied: platformdirs<4,>=2.4 in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from virtualenv>=20.0.24->ray) (3.2.0)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from virtualenv>=20.0.24->ray) (0.3.6)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jsonschema->ray) (0.19.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from requests->ray) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from requests->ray) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from requests->ray) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ajvendetta\\appdata\\roaming\\python\\python310\\site-packages (from requests->ray) (3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\ajvendetta\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "THETA_LEFT = 0.5\n",
    "THETA_RIGHT = 0\n",
    "MAX_STEPS = 300 \n",
    "OMEGA = 1 \n",
    "STEPS_IN_CYCLE= 30 \n",
    "a_swing = 0 \n",
    "b_swing = 0.5\n",
    "a_stance = 0.5\n",
    "b_stance = 1\n",
    "FORWARD_QUARTERNIONS = np.array([1, 0, 0, 0])\n",
    "KAPPA = 8 \n",
    "X_VEL = 0.5\n",
    "Z_VEL = 0\n",
    "c_swing_frc = -1 \n",
    "c_stance_frc = 0\n",
    "c_swing_spd = 0\n",
    "c_stance_spd = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_CAMERA_CONFIG = {\n",
    "    \"trackbodyid\": 0,  # use the body id of Cassie\n",
    "    \"distance\": 4.0,\n",
    "    \"lookat\": np.array((0.0, 0.0, 0.85)),  # adjust the height to match Cassie's height\n",
    "    \"elevation\": -20.0,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class CassieEnv(MujocoEnv):\n",
    "    metadata = {\n",
    "        \"render_modes\": [\n",
    "            \"human\",\n",
    "            \"rgb_array\",\n",
    "            \"depth_array\",\n",
    "        ],\n",
    "        \"render_fps\": 100,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def vm_cdf(self,x, mu, kappa, num_points=1000):\n",
    "        \"\"\"Computes the CDF of the von Mises distribution.\n",
    "\n",
    "        Parameters:\n",
    "        x (float or array-like): Value(s) at which to evaluate the CDF.\n",
    "        mu (float): Mean parameter of the von Mises distribution.\n",
    "        kappa (float): Concentration parameter of the von Mises distribution.\n",
    "        num_points (int, optional): Number of points to use in the numerical integration. Default is 1000.\n",
    "\n",
    "        Returns:\n",
    "        float or array-like: The CDF of the von Mises distribution evaluated at `x`.\n",
    "        \"\"\"\n",
    "        \n",
    "        def besseli0(x):\n",
    "            \"\"\"Approximation of the Bessel I0 function.\"\"\"\n",
    "            ax = np.abs(x)\n",
    "            if ax < 3.75:\n",
    "                y = x / 3.75\n",
    "                y2 = y ** 2\n",
    "                return 1.0 + y2 * (3.5156229 + y2 * (3.0899424 + y2 * (1.2067492 + y2 * (0.2659732 + y2 * (0.0360768 + y2 * 0.0045813)))))\n",
    "            else:\n",
    "                y = 3.75 / ax\n",
    "                return (np.exp(ax) / np.sqrt(ax)) * (0.39894228 + y * (0.01328592 + y * (0.00225319 + y * (-0.00157565 + y * (0.00916281 + y * (-0.02057706 + y * (0.02635537 + y * (-0.01647633 + y * 0.00392377))))))))\n",
    "\n",
    "        def integrand(t):\n",
    "            return np.exp(kappa * np.cos(t - mu)) / besseli0(kappa)\n",
    "\n",
    "        if isinstance(x, (int, float)):\n",
    "            # Compute the numerical integral using the trapezoidal rule\n",
    "            xvals = np.linspace(-np.pi, x, num_points)\n",
    "            yvals = integrand(xvals)\n",
    "            integral = np.trapz(yvals, xvals)\n",
    "\n",
    "            # Compute the normalization constant\n",
    "            zvals = integrand(np.linspace(-np.pi, np.pi, num_points))\n",
    "            normalization = np.trapz(zvals, np.linspace(-np.pi, np.pi, num_points))\n",
    "\n",
    "            # Return the CDF\n",
    "            return integral / normalization\n",
    "        else:\n",
    "            cdf_values = []\n",
    "            for xi in x:\n",
    "                # Compute the numerical integral using the trapezoidal rule\n",
    "                xvals = np.linspace(-np.pi, xi, num_points)\n",
    "                yvals = integrand(xvals)\n",
    "                integral = np.trapz(yvals, xvals)\n",
    "\n",
    "                # Compute the normalization constant\n",
    "                zvals = integrand(np.linspace(-np.pi, np.pi, num_points))\n",
    "                normalization = np.trapz(zvals, np.linspace(-np.pi, np.pi, num_points))\n",
    "\n",
    "                # Append the CDF value to the list\n",
    "                cdf_values.append(integral / normalization)\n",
    "            return np.array(cdf_values)\n",
    "\n",
    "    def __init__(self,config,  **kwargs):\n",
    "        utils.EzPickle.__init__(self, config, **kwargs)\n",
    "\n",
    "        self._forward_reward_weight = config.get(\"forward_reward_weight\", 1.25)\n",
    "        self._ctrl_cost_weight = config.get(\"ctrl_cost_weight\", 0.1)\n",
    "        self._healthy_reward = config.get(\"healthy_reward\", 5.0)\n",
    "        self._terminate_when_unhealthy = config.get(\"terminate_when_unhealthy\", True)\n",
    "        self._healthy_z_range = config.get(\"healthy_z_range\", (0.5, 2.0))\n",
    "        actuator_ranges = {\n",
    "            'left-hip-roll': [-4.5, 4.5],\n",
    "            'left-hip-yaw': [-4.5, 4.5],\n",
    "            'left-hip-pitch': [-12.2, 12.2],\n",
    "            'left-knee': [-12.2, 12.2],\n",
    "            'left-foot': [-0.9, 0.9],\n",
    "            'right-hip-roll': [-4.5, 4.5],\n",
    "            'right-hip-yaw': [-4.5, 4.5],\n",
    "            'right-hip-pitch': [-12.2, 12.2],\n",
    "            'right-knee': [-12.2, 12.2],\n",
    "            'right-foot': [-0.9, 0.9]\n",
    "        }\n",
    "        \n",
    "        # create the action space using the actuator ranges\n",
    "        low = [actuator_ranges[key][0] for key in actuator_ranges.keys()]\n",
    "        high = [actuator_ranges[key][1] for key in actuator_ranges.keys()]\n",
    "        self.action_space = gym.spaces.Box(np.array(low), np.array(high), dtype=np.float32)\n",
    "        self._reset_noise_scale = config.get(\"reset_noise_scale\", 1e-2)\n",
    "        self.phi = 0\n",
    "        self._exclude_current_positions_from_observation = config.get(\"exclude_current_positions_from_observation\", True)\n",
    "        self.steps =0\n",
    "        self.previous_action = np.zeros (10)\n",
    "        observation_space = Box(low=-np.inf, high=np.inf, shape=(31,), dtype=np.float64)\n",
    "        MujocoEnv.__init__(self, config.get(\"model_path\",\"cassie.xml\") ,20,render_mode=config.get(\"render_mode\",None), observation_space=observation_space, default_camera_config=DEFAULT_CAMERA_CONFIG, **kwargs)\n",
    "\n",
    "\n",
    "    @property\n",
    "    def healthy_reward(self):\n",
    "        return float(self.is_healthy or self._terminate_when_unhealthy) * self._healthy_reward\n",
    "\n",
    "    @property\n",
    "    def is_healthy(self):\n",
    "        min_z, max_z = self._healthy_z_range\n",
    "        is_healthy = min_z < self.data.qpos[2] < max_z\n",
    "\n",
    "        return is_healthy\n",
    "\n",
    "    @property\n",
    "    def terminated(self):\n",
    "        terminated = (not self.is_healthy) if (self._terminate_when_unhealthy or self.steps>MAX_STEPS)  else False\n",
    "        return terminated\n",
    "    def _get_obs(self):\n",
    "        '''The sensor data are the following \n",
    "        left-foot-input [-2.20025499]\n",
    "        left-foot-output [-0.0440051]\n",
    "        left-hip-pitch-input [0.03050987]\n",
    "        left-hip-roll-input [0.2013339]\n",
    "        left-hip-yaw-input [0.30352121]\n",
    "        left-knee-input [-12.57921603]\n",
    "        left-shin-output [-0.00254359]\n",
    "        left-tarsus-output [1.01621498]\n",
    "        pelvis-angular-velocity [-0.66091646  0.09304743 -0.14707221]\n",
    "        pelvis-linear-acceleration [  0.18789681 -11.51133484  -0.64882624]\n",
    "        pelvis-magnetometer [ 3.71266894e-04 -4.99997057e-01 -1.67494055e-03]\n",
    "        pelvis-orientation [ 9.99998508e-01 -1.67501875e-03  2.04083784e-04 -3.70925603e-04]\n",
    "        right-foot-input [-2.18139208]\n",
    "        right-foot-output [-0.04362784]\n",
    "        right-hip-pitch-input [0.00453772]\n",
    "        right-hip-roll-input [0.12788968]\n",
    "        right-hip-yaw-input [0.08293241]\n",
    "        right-knee-input [-12.53914917]\n",
    "        right-shin-output [-0.00094644]\n",
    "        right-tarsus-output [1.01240756]    \n",
    "        '''\n",
    "        p =np.array ([np.sin((2*np.pi*(self.phi+THETA_LEFT))/STEPS_IN_CYCLE),np.sin((2*np.pi*(self.phi+THETA_RIGHT))/STEPS_IN_CYCLE)])\n",
    "\n",
    "        #getting the read positions of the sensors and concatenate the lists\n",
    "        return np.concatenate([self.data.sensordata,p])\n",
    "\n",
    "    def get_pos(self):\n",
    "                \n",
    "        #Robot State\n",
    "        qpos = self.data.qpos.flat.copy()\n",
    "        qvel = self.data.qvel.flat.copy()\n",
    "\n",
    "        #Desired velocity\n",
    "\n",
    "\n",
    "        #Phase ratios and clock inputs\n",
    "\n",
    "        #p = {sin(2pi(phi+theta_left)/L),sin(2pi(phi+theta_right)/L)} where L is the number of timesteps in each period\n",
    "        p = (np.sin((2*np.pi*(self.phi+THETA_LEFT))/STEPS_IN_CYCLE),np.sin((2*np.pi*(self.phi+THETA_RIGHT))/STEPS_IN_CYCLE))\n",
    "        '''\n",
    "\t\tPosition [1], [2] \t\t\t\t-> Pelvis y, z\n",
    "\t\t\t\t [3], [4], [5], [6] \t-> Pelvis Orientation qw, qx, qy, qz\n",
    "\t\t\t\t [7], [8], [9]\t\t\t-> Left Hip Roll (Motor[0]), Yaw (Motor[1]), Pitch (Motor[2])\n",
    "\t\t\t\t [14]\t\t\t\t\t-> Left Knee   \t(Motor[3])\n",
    "\t\t\t\t [15]\t\t\t\t\t-> Left Shin   \t(Joint[0])\n",
    "\t\t\t\t [16]\t\t\t\t\t-> Left Tarsus \t(Joint[1])\n",
    "\t\t\t\t [20]\t\t\t\t\t-> Left Foot   \t(Motor[4], Joint[2])\n",
    "\t\t\t\t [21], [22], [23]\t\t-> Right Hip Roll (Motor[5]), Yaw (Motor[6]), Pitch (Motor[7])\n",
    "\t\t\t\t [28]\t\t\t\t\t-> Rigt Knee   \t(Motor[8])\n",
    "\t\t\t\t [29]\t\t\t\t\t-> Rigt Shin   \t(Joint[3])\n",
    "\t\t\t\t [30]\t\t\t\t\t-> Rigt Tarsus \t(Joint[4])\n",
    "\t\t\t\t [34]\t\t\t\t\t-> Rigt Foot   \t(Motor[9], Joint[5])\n",
    "\t\t''' \n",
    "        pos_index = np.array([1,2,3,4,5,6,7,8,9,14,15,16,20,21,22,23,28,29,30,34])\n",
    "        \n",
    "        '''\n",
    "\t\tVelocity [0], [1], [2] \t\t\t-> Pelvis x, y, z\n",
    "\t\t\t\t [3], [4], [5]\t\t \t-> Pelvis Orientation wx, wy, wz\n",
    "\t\t\t\t [6], [7], [8]\t\t\t-> Left Hip Roll (Motor[0]), Yaw (Motor[1]), Pitch (Motor[2])\n",
    "\t\t\t\t [12]\t\t\t\t\t-> Left Knee   \t(Motor[3])\n",
    "\t\t\t\t [13]\t\t\t\t\t-> Left Shin   \t(Joint[0])\n",
    "\t\t\t\t [14]\t\t\t\t\t-> Left Tarsus \t(Joint[1])\n",
    "\t\t\t\t [18]\t\t\t\t\t-> Left Foot   \t(Motor[4], Joint[2])\n",
    "\t\t\t\t [19], [20], [21]\t\t-> Right Hip Roll (Motor[5]), Yaw (Motor[6]), Pitch (Motor[7])\n",
    "\t\t\t\t [25]\t\t\t\t\t-> Rigt Knee   \t(Motor[8])\n",
    "\t\t\t\t [26]\t\t\t\t\t-> Rigt Shin   \t(Joint[3])\n",
    "\t\t\t\t [27]\t\t\t\t\t-> Rigt Tarsus \t(Joint[4])\n",
    "\t\t\t\t [31]\t\t\t\t\t-> Rigt Foot   \t(Motor[9], Joint[5])\n",
    "\t\t''' \n",
    "        vel_index = np.array([0,1,2,3,4,5,6,7,8,12,13,14,18,19,20,21,25,26,27,31])\n",
    "        return np.concatenate([qpos[pos_index], qvel[vel_index],[p[0],p[1]]])\n",
    "    \n",
    "\n",
    "    def von_mises(a,kappa,phi ):\n",
    "        vm = torch.distributions.von_mises(a,kappa)\n",
    "        return vm.cdf(phi)\n",
    "    \n",
    "    def compute_reward(self,action):\n",
    "\n",
    "        # Extract some proxies\n",
    "        qpos = self.data.qpos.flat.copy()\n",
    "        qvel = self.data.qvel.flat.copy()\n",
    "        pos_index = np.array([1,2,3,4,5,6,7,8,9,14,15,16,20,21,22,23,28,29,30,34])\n",
    "        vel_index = np.array([0,1,2,3,4,5,6,7,8,12,13,14,18,19,20,21,25,26,27,31])\n",
    "        \n",
    "        qpos = qpos[pos_index]\n",
    "        qvel=qvel[vel_index]\n",
    "\n",
    "\n",
    "        #Feet Contact Forces \n",
    "        contact_force_right_foot = np.zeros(6)\n",
    "        m.mj_contactForce(self.model,self.data,0,contact_force_right_foot)\n",
    "        contact_force_left_foot = np.zeros(6)\n",
    "        m.mj_contactForce(self.model,self.data,1,contact_force_left_foot)\n",
    "\n",
    "\n",
    "        # Update previous position\n",
    "\n",
    "        ######## Odometry xy reward ########\n",
    "        q_vx = 1-np.exp(-2*OMEGA*np.linalg.norm(np.array([qvel[0]]) - np.array([X_VEL]))**2)\n",
    "        ################\n",
    "\n",
    "        ######## Odometry xy reward ########\n",
    "        q_vy = 1-np.exp(-2*OMEGA*np.linalg.norm(np.array([qvel[2]]) - np.array([Z_VEL]))**2)\n",
    "        ################\n",
    "\n",
    "        q_left_frc = 1.0 - np.exp(-OMEGA * np.linalg.norm(contact_force_left_foot)**2/4000)\n",
    "        q_right_frc = 1.0 - np.exp(-OMEGA * np.linalg.norm(contact_force_right_foot)**2/4000)\n",
    "        q_left_spd = 1.0 - np.exp(-OMEGA * np.linalg.norm(qvel[12])**2)\n",
    "        q_right_spd = 1.0 - np.exp(-OMEGA * np.linalg.norm(qvel[19])**2)\n",
    "        \n",
    "\n",
    "        q_action_diff = 1 - np.exp(-5*np.linalg.norm(action-self.previous_action))\n",
    "        q_orientation = 1 -np.exp(-3*(1-((self.data.sensor('pelvis-orientation').data.T)@(FORWARD_QUARTERNIONS))**2))\n",
    "        q_torque = 1 - np.exp(-0.05*np.linalg.norm(action))\n",
    "        q_pelvis_acc = 1 - np.exp(-0.10*(np.linalg.norm(self.data.sensor('pelvis-angular-velocity').data) + np.linalg.norm(self.data.sensor('pelvis-linear-acceleration').data)))\n",
    "        \n",
    "\n",
    "        I = lambda phi,a,b : self.vm_cdf(phi,a,KAPPA)*(1-self.vm_cdf(phi,b,KAPPA))\n",
    "\n",
    "        I_swing_frc = lambda phi : I(phi,a_swing,b_swing)\n",
    "        I_swing_spd = lambda phi : I(phi, a_swing,b_swing)\n",
    "        I_stance_spd = lambda phi : I(phi, a_stance,b_stance)\n",
    "        I_stance_frc = lambda phi : I(phi, a_stance,b_stance)\n",
    "        C_frc = lambda phi : c_swing_frc * I_swing_frc(phi) + c_stance_frc * I_stance_frc(phi) + c_stance_frc * I_stance_frc(phi)\n",
    "\n",
    "        C_spd = lambda phi :  c_swing_spd * I_swing_spd(phi) + c_stance_spd * I_stance_spd(phi)\n",
    "        \n",
    "        R_cmd = -1.0*q_vx-1.0*q_vy-1.0*q_orientation\n",
    "\n",
    "        R_smooth = -1.0*q_action_diff - 1.0* q_torque - 1.0*q_pelvis_acc\n",
    "\n",
    "\n",
    "        R_biped = 0\n",
    "        R_biped += C_frc(self.phi+THETA_LEFT) * q_left_frc\n",
    "        R_biped += C_frc(self.phi+THETA_RIGHT) * q_right_frc\n",
    "        R_biped += C_spd(self.phi+THETA_LEFT) * q_left_spd\n",
    "        R_biped += C_spd(self.phi+THETA_RIGHT) * q_right_spd\n",
    "\n",
    "        reward = 1.5  + 0.5 * R_biped  +  0.375* R_cmd +  0.125* R_smooth\n",
    "        #store all used values with their names in a dictionary\n",
    "        self.rewards = {\n",
    "            'R_biped': R_biped,\n",
    "            'R_cmd': R_cmd,\n",
    "            'R_smooth': R_smooth,\n",
    "            'q_vx': q_vx,\n",
    "            'q_vy': q_vy,\n",
    "            'q_orientation': q_orientation,\n",
    "            'q_action_diff': q_action_diff,\n",
    "            'q_torque': q_torque,\n",
    "            'q_pelvis_acc': q_pelvis_acc,\n",
    "            'q_left_frc': q_left_frc,\n",
    "            'q_right_frc': q_right_frc,\n",
    "            'q_left_spd': q_left_spd,\n",
    "            'q_right_spd': q_right_spd,\n",
    "            'reward': reward,\n",
    "            'contact_force_left_foot': np.linalg.norm(contact_force_left_foot)**2/4000\n",
    "        }\n",
    "        return reward\n",
    "    \n",
    "\n",
    "    def step(self, action):\n",
    "        #clip the action to the ranges in action_space\n",
    "        action = np.clip(action, self.action_space.low, self.action_space.high)\n",
    "        \n",
    "        self.do_simulation(action, self.frame_skip)\n",
    "\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        \n",
    "        reward = self.compute_reward(action)\n",
    "\n",
    "        terminated = self.terminated\n",
    "\n",
    "        self.steps +=1 \n",
    "        self.phi+= 1.0/STEPS_IN_CYCLE\n",
    "        self.phi = self.phi % 1 \n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "        self.previous_action = action \n",
    "        return observation, reward, terminated, False, {}\n",
    "\n",
    "    def reset_model(self):\n",
    "\n",
    "        m.mj_inverse(self.model, self.data)\n",
    "        noise_low = -self._reset_noise_scale\n",
    "        noise_high = self._reset_noise_scale\n",
    "        self.previous_action = np.zeros (10)\n",
    "        self.phi = 0 \n",
    "        self.steps = 0 \n",
    "        \n",
    "        qpos = self.init_qpos + self.np_random.uniform(low=noise_low, high=noise_high, size=self.model.nq)\n",
    "        qvel = self.init_qvel + self.np_random.uniform(low=noise_low, high=noise_high, size=self.model.nv)\n",
    "        self.set_state(qpos, qvel)\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PPO_cassie-v0_2023-04-01_10-28-48tc384_ae\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "log_dir = \"C:\\\\Users\\\\Ajvendetta\\\\ray_results\\\\\"\n",
    "sim_dir = \"sim/\"\n",
    "#load the trainer from the latest checkpoint if exists \n",
    "#get the full directory of latest modified directory in the log_dir \n",
    "latest_log_directory = max([d for d in os.listdir(log_dir) if d.startswith(\"PPO_\")], default=0)\n",
    "print(latest_log_directory)\n",
    "\n",
    "#get the latest directory in the latest log directory\n",
    "latest_directory = max([d.split(\"_\")[-1] for d in os.listdir(os.path.join(log_dir, latest_log_directory)) if d.startswith(\"checkpoint\")], default=0)\n",
    "#load the trainer from the latest checkpoint\n",
    "checkpoint_path = os.path.join(log_dir, latest_log_directory, \"checkpoint_{}\\\\\".format(latest_directory, latest_directory))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 10:29:38,441\tINFO worker.py:1553 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "#register the environment in rllib \n",
    "\n",
    "#import the necessary libraries to initialize ray and register_env\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "\n",
    "#initialize ray and choose the log directory\n",
    "\n",
    "import ray\n",
    "\n",
    "ray.init(ignore_reinit_error=True)\n",
    "\n",
    "register_env(\"cassie-v0\", lambda config: CassieEnv(config))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ajvendetta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "cassie = CassieEnv({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.54497552e-02,  1.53220660e-01,  6.83145995e-02, -1.27160808e+01,\n",
       "        -4.53372455e-01, -2.53177524e-03,  1.00411972e+00, -9.06744911e-03,\n",
       "         4.63464087e-02, -2.12303746e-01,  3.97857744e-02, -1.26399549e+01,\n",
       "         7.35291439e-02, -1.18780804e-03,  1.00689897e+00,  1.47058288e-03,\n",
       "         9.99902777e-01,  7.08705614e-03, -7.25375255e-03, -9.57048440e-03,\n",
       "        -7.32288179e-03,  3.61898247e-03, -8.69224831e-03,  1.12251159e+00,\n",
       "        -6.44420242e-01, -5.03496925e-01,  9.62096167e-03, -4.99858179e-01,\n",
       "         7.01694519e-03,  1.04528463e-01,  0.00000000e+00]),\n",
       " {})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cassie.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cassie.render_mode = \"rgb_array\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"framework\": \"torch\",\n",
    "    \"log_level\" : \"WARN\",\n",
    "    \"num_gpus\": 1,\n",
    "    \"num_cpus\": 14,\n",
    "    \"num_workers\": 6,\n",
    "    \"num_envs_per_worker\": 1,\n",
    "    \"rollout_fragment_length\": 200,\n",
    "    \"train_batch_size\": 32000,\n",
    "    \"sgd_minibatch_size\": 8000,\n",
    "    \"num_sgd_iter\": 10,\n",
    "    \"lr\": 0.0003,\n",
    "    \"optimizer\": {\n",
    "        \"type\": \"Adam\",\n",
    "        \"lr\": 3e-4,\n",
    "        \"epsilon\": 1e-5\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"conv_filters\": None,\n",
    "        \"fcnet_activation\": \"relu\",\n",
    "        \"fcnet_hiddens\": [256, 256],\n",
    "        \"use_lstm\": False,\n",
    "        \"vf_share_layers\": False,\n",
    "        \"free_log_std\": True\n",
    "\n",
    "    },\n",
    "    \"entropy_coeff\": 0.01,\n",
    "    \"gamma\": 0.99,\n",
    "    \"lambda\": 0.95,\n",
    "    \"kl_coeff\": 0.5,\n",
    "    \"clip_param\": 0.2,\n",
    "    \"vf_clip_param\": 10.0,\n",
    "    \"grad_clip\": 0.5,\n",
    "    \"kl_target\": 0.01,\n",
    "    \"batch_mode\": \"truncate_episodes\",\n",
    "    \"observation_filter\": \"NoFilter\",\n",
    "    \"reuse_actors\": True,\n",
    "    \"disable_env_checking\" : True,\n",
    "    \"num_gpus_per_worker\": 0.1,\n",
    "    \"num_cpus_per_worker\": 1,\n",
    "    \"evaluation_config\": {\n",
    "        \"explore\": True,\n",
    "        \"evaluation_interval\": 10,\n",
    "        \"evaluation_num_episodes\": 20\n",
    "\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.agents.ppo import PPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.82011204e-01,  1.24948907e-01, -7.31314775e-02, -1.25338730e+01,\n",
       "        -1.22917315e-01,  6.83173507e-03,  1.02226337e+00, -2.45834630e-03,\n",
       "         1.16215329e-01, -1.20071298e-01,  1.98299371e-02, -1.26336206e+01,\n",
       "        -4.33207710e-01,  5.97009288e-03,  1.00612467e+00, -8.66415421e-03,\n",
       "         9.99970848e-01,  2.53493641e-03,  1.97968083e-03,  6.92521951e-03,\n",
       "        -8.59968402e-03,  3.09628481e-03,  1.32623283e-03, -1.66774932e+00,\n",
       "         6.25118263e-01, -1.02599147e+00, -6.93003599e-03, -4.99945615e-01,\n",
       "         2.52115279e-03,  1.04528463e-01,  0.00000000e+00]),\n",
       " {})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cassie.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1.78343461e-01,  1.30990798e-01, -1.74725947e-02, -1.24745360e+01,\n",
       "        -2.32673842e+00, -4.43422491e-03,  1.02285782e+00, -4.65347683e-02,\n",
       "         1.14000460e-01, -1.32991845e-01,  1.67178017e-02, -1.25970243e+01,\n",
       "        -2.61473555e+00, -8.30994176e-04,  1.01607173e+00, -5.22947110e-02,\n",
       "         9.99970438e-01,  2.53139978e-03,  1.48548653e-03,  7.10694218e-03,\n",
       "         4.47146348e-03, -1.52133555e-01,  2.66753885e-02,  6.61395609e-01,\n",
       "         8.35702734e-02,  2.79337842e-01, -7.11049244e-03, -4.99943083e-01,\n",
       "         2.52076768e-03,  1.04528463e-01,  0.00000000e+00]),\n",
       " 1.0553136166729047,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cassie.step([0,0,0,0,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 10:29:42,992\tWARNING algorithm_config.py:596 -- Cannot create PPOConfig from given `config_dict`! Property num_cpus not supported.\n",
      "2023-04-01 10:29:42,993\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='cassie-v0', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('cassie-v0').build()` instead. This will raise an error in the future!\n",
      "2023-04-01 10:29:43,039\tINFO algorithm.py:506 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18560)\u001b[0m c:\\Users\\Ajvendetta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18560)\u001b[0m   gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18580)\u001b[0m c:\\Users\\Ajvendetta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18580)\u001b[0m   gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=12452)\u001b[0m c:\\Users\\Ajvendetta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=12452)\u001b[0m   gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18600)\u001b[0m c:\\Users\\Ajvendetta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18600)\u001b[0m   gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18540)\u001b[0m c:\\Users\\Ajvendetta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18540)\u001b[0m   gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18304)\u001b[0m c:\\Users\\Ajvendetta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "\u001b[2m\u001b[36m(RolloutWorker pid=18304)\u001b[0m   gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "2023-04-01 10:30:05,108\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.evaluation(evaluation_num_episodes=..)` has been deprecated. Use `AlgorithmConfig.evaluation(evaluation_duration=.., evaluation_duration_unit='episodes')` instead. This will raise an error in the future!\n",
      "c:\\Users\\Ajvendetta\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gymnasium\\spaces\\box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "2023-04-01 10:30:05,603\tINFO trainable.py:172 -- Trainable.setup took 22.560 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2023-04-01 10:30:05,626\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "trainer = PPOTrainer(config=config, env=\"cassie-v0\")\n",
    "#load the trainer from the latest checkpoint if exists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(checkpoint_path):\n",
    "    trainer.restore(checkpoint_path)\n",
    "    print(\"Checkpoint loaded from\", checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Reward Mean for iteration 1 is 6.654005760785358\n",
      "Episode Reward Mean for iteration 2 is 7.275387849894402\n",
      "Episode Reward Mean for iteration 3 is 7.9648934103879325\n",
      "Episode Reward Mean for iteration 4 is 8.339493705991478\n",
      "Episode Reward Mean for iteration 5 is 8.756730428261935\n",
      "Episode Reward Mean for iteration 6 is 9.01290115994463\n",
      "Episode Reward Mean for iteration 7 is 9.317872192459259\n",
      "Episode Reward Mean for iteration 8 is 9.927584672542487\n",
      "Episode Reward Mean for iteration 9 is 10.246554929026454\n",
      "Episode Reward Mean for iteration 10 is 10.437885120454506\n",
      "Checkpoint saved at C:\\Users\\Ajvendetta/ray_results\\PPO_cassie-v0_2023-04-01_10-29-421bdrl2im\\checkpoint_000010\n",
      "Episode Reward Mean for iteration 11 is 10.662530381328125\n",
      "Episode Reward Mean for iteration 12 is 10.747956414462896\n",
      "Episode Reward Mean for iteration 13 is 10.807608404600911\n",
      "Episode Reward Mean for iteration 14 is 11.294202061402181\n",
      "Episode Reward Mean for iteration 15 is 11.799049265472673\n",
      "Episode Reward Mean for iteration 16 is 12.012440527653595\n",
      "Episode Reward Mean for iteration 17 is 12.415618529656722\n",
      "Episode Reward Mean for iteration 18 is 12.639282959556688\n",
      "Episode Reward Mean for iteration 19 is 13.06022338986298\n",
      "Episode Reward Mean for iteration 20 is 13.073303841492077\n",
      "Checkpoint saved at C:\\Users\\Ajvendetta/ray_results\\PPO_cassie-v0_2023-04-01_10-29-421bdrl2im\\checkpoint_000020\n",
      "Episode Reward Mean for iteration 21 is 13.673566487999375\n",
      "Episode Reward Mean for iteration 22 is 13.697084131037306\n",
      "Episode Reward Mean for iteration 23 is 13.98394105922774\n",
      "Episode Reward Mean for iteration 24 is 14.402015853817819\n",
      "Episode Reward Mean for iteration 25 is 14.806073623286595\n",
      "Episode Reward Mean for iteration 26 is 14.922321920426658\n",
      "Episode Reward Mean for iteration 27 is 15.003266252737122\n",
      "Episode Reward Mean for iteration 28 is 15.438024830408022\n",
      "Episode Reward Mean for iteration 29 is 15.669393070768722\n",
      "Episode Reward Mean for iteration 30 is 15.958108315591266\n",
      "Checkpoint saved at C:\\Users\\Ajvendetta/ray_results\\PPO_cassie-v0_2023-04-01_10-29-421bdrl2im\\checkpoint_000030\n",
      "Episode Reward Mean for iteration 31 is 16.039552612718776\n",
      "Episode Reward Mean for iteration 32 is 15.833491552135897\n",
      "Episode Reward Mean for iteration 33 is 16.652900483057685\n",
      "Episode Reward Mean for iteration 34 is 17.2465644476858\n",
      "Episode Reward Mean for iteration 35 is 17.927596938331227\n",
      "Episode Reward Mean for iteration 36 is 17.558655966093113\n",
      "Episode Reward Mean for iteration 37 is 18.52975632013802\n",
      "Episode Reward Mean for iteration 38 is 18.723038229482974\n",
      "Episode Reward Mean for iteration 39 is 18.70072751528216\n",
      "Episode Reward Mean for iteration 40 is 17.695909691043642\n",
      "Checkpoint saved at C:\\Users\\Ajvendetta/ray_results\\PPO_cassie-v0_2023-04-01_10-29-421bdrl2im\\checkpoint_000040\n",
      "Episode Reward Mean for iteration 41 is 18.14558007802166\n",
      "Episode Reward Mean for iteration 42 is 17.88393844253214\n",
      "Episode Reward Mean for iteration 43 is 19.123185245641256\n",
      "Episode Reward Mean for iteration 44 is 19.787607828343205\n",
      "Episode Reward Mean for iteration 45 is 20.63156906374243\n",
      "Episode Reward Mean for iteration 46 is 21.487467837507147\n",
      "Episode Reward Mean for iteration 47 is 22.419947337171262\n",
      "Episode Reward Mean for iteration 48 is 23.026708389401044\n",
      "Episode Reward Mean for iteration 49 is 23.1878303238044\n",
      "Episode Reward Mean for iteration 50 is 23.447355856485938\n",
      "Checkpoint saved at C:\\Users\\Ajvendetta/ray_results\\PPO_cassie-v0_2023-04-01_10-29-421bdrl2im\\checkpoint_000050\n",
      "Episode Reward Mean for iteration 51 is 24.13005147702451\n",
      "Episode Reward Mean for iteration 52 is 25.380297919920377\n",
      "Episode Reward Mean for iteration 53 is 25.23699880622065\n",
      "Episode Reward Mean for iteration 54 is 25.70568260939039\n",
      "Episode Reward Mean for iteration 55 is 25.87489816927201\n",
      "Episode Reward Mean for iteration 56 is 25.722978427809277\n",
      "Episode Reward Mean for iteration 57 is 25.720601508566332\n",
      "Episode Reward Mean for iteration 58 is 27.840614280628408\n",
      "Episode Reward Mean for iteration 59 is 27.412951862861174\n",
      "Episode Reward Mean for iteration 60 is 28.854713927050668\n",
      "Checkpoint saved at C:\\Users\\Ajvendetta/ray_results\\PPO_cassie-v0_2023-04-01_10-29-421bdrl2im\\checkpoint_000060\n",
      "Episode Reward Mean for iteration 61 is 30.050514991556106\n",
      "Episode Reward Mean for iteration 62 is 31.03690092167975\n",
      "Episode Reward Mean for iteration 63 is 30.187993551614348\n",
      "Episode Reward Mean for iteration 64 is 29.819031819941785\n",
      "Episode Reward Mean for iteration 65 is 30.574671905775347\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Training loop\n",
    "\n",
    "max_test_i = 0\n",
    "checkpoint_frequency = 10\n",
    "simulation_frequency = 20\n",
    "env = CassieEnv({})\n",
    "env.render_mode = \"rgb_array\"\n",
    "\n",
    "\n",
    "# Find the latest directory named test_i in the sim directory\n",
    "latest_directory = max([int(d.split(\"_\")[-1]) for d in os.listdir(sim_dir) if d.startswith(\"test_\")], default=0)\n",
    "max_test_i = latest_directory + 1\n",
    "\n",
    "# Create folder for test\n",
    "test_dir = os.path.join(sim_dir, \"test_{}\".format(max_test_i))\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Define video codec and framerate\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "fps = 30\n",
    "\n",
    "\n",
    "\n",
    "# Set initial iteration count\n",
    "i = trainer.iteration if hasattr(trainer, \"iteration\") else 0\n",
    "\n",
    "while True:\n",
    "    # Train for one iteration\n",
    "    result = trainer.train()\n",
    "    i += 1\n",
    "    print(\"Episode Reward Mean for iteration {} is {}\".format(i, result[\"episode_reward_mean\"]))\n",
    "\n",
    "    # Save model every 10 epochs\n",
    "    if i % checkpoint_frequency == 0:\n",
    "        checkpoint_path = trainer.save()\n",
    "        print(\"Checkpoint saved at\", checkpoint_path)\n",
    "\n",
    "    # Run a test every 20 epochs\n",
    "    if i % simulation_frequency == 0:\n",
    "\n",
    "        # Run test\n",
    "        video_path = os.path.join(test_dir, \"sim_{}.mp4\".format(i))\n",
    "\n",
    "        env.reset()\n",
    "        obs = env.reset()[0]\n",
    "        done = False\n",
    "        frames = []\n",
    "\n",
    "        while not done:\n",
    "            action = trainer.compute_single_action(obs)\n",
    "            obs, _, done, _, _ = env.step(action)\n",
    "            frame = env.render()\n",
    "            frames.append(frame)\n",
    "\n",
    "        env.close()\n",
    "\n",
    "        # Save frames as video\n",
    "        height, width, _ = frames[0].shape\n",
    "        video_writer = cv2.VideoWriter(video_path, fourcc, fps, (width, height))\n",
    "        for frame in frames:\n",
    "            video_writer.write(frame)\n",
    "        video_writer.release()\n",
    "\n",
    "        # Increment test index\n",
    "        max_test_i += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
